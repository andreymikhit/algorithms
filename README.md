# algorithms
GeekBrains
# Алгоритмы анализа данных

### Урок 1. Алгоритм линейной регрессии. Градиентный спуск
Реализовать оптимизацию методом градиентного спуска для x^2(np.sin(0,5_x)^2+1). Какие параметры шага и количества итераций оптимальны? При каких значениях шага оптимизиция не выходит из локальных минимумов? Подробные условия смотрите в .ipynb файле, приложенном к материалам.

###

###

###

###

###

###

###
